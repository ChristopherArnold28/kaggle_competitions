{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"fare_amount\"] < 100]\n",
    "data = data[data[\"fare_amount\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an item this large is too large to work with \n",
    "#finding hyper params use 10k\n",
    "data = data.sample(1000000)\n",
    "#training for final submission use 1mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.distplot(data[\"fare_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#75% of our data exists with fares below $12.50 so it would make sense to do a cutoff at approximately \n",
    "#$100 and that should capture everything\n",
    "\n",
    "#we notice there are a few blips on our distribution chart between $40 and $60\n",
    "#whether those are legitimate or not is another question, we will look at the other features in our\n",
    "#data set and start to eliminate records that do not name sense in those cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases to eliminate\n",
    "#passengers over 8\n",
    "#we are only dealing with new york city so latitudes and longitudes outside of a small realm is\n",
    "#not realistic\n",
    "#latitude more than 42 and less than 35 needs to be removed\n",
    "#longitude less than -76 or greater than -73 needs to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"pickup_latitude\"] <43) & (data[\"pickup_latitude\"] > 39)]\n",
    "data = data[(data[\"dropoff_latitude\"] <43) & (data[\"dropoff_latitude\"] > 39)]\n",
    "data = data[(data[\"pickup_longitude\"] < -73) & (data[\"pickup_longitude\"] > - 75)]\n",
    "data = data[(data[\"dropoff_longitude\"] <-73) & (data[\"dropoff_longitude\"] > -75)]\n",
    "data = data[(data[\"passenger_count\"] > 0) & (data[\"passenger_count\"] < 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"fare_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "def get_distance(row):\n",
    "    distance = haversine([row[\"pickup_latitude\"], row[\"pickup_longitude\"]],[row[\"dropoff_latitude\"], row[\"dropoff_longitude\"]])\n",
    "    distance_miles = distance * 3280.84/5280\n",
    "    return distance_miles\n",
    "\n",
    "def distance_from_pickup(row, loc_lat, loc_lng):\n",
    "    distance = haversine([row[\"pickup_latitude\"], row[\"pickup_longitude\"]], [loc_lat, loc_lng])\n",
    "    distance_miles = distance* 3280.84/5280\n",
    "    return distance_miles\n",
    "    \n",
    "def distance_from_dropoff(row, loc_lat, loc_lng):\n",
    "    distance = haversine([row[\"dropoff_latitude\"], row[\"dropoff_longitude\"]], [loc_lat, loc_lng])\n",
    "    distance_miles = distance* 3280.84/5280\n",
    "    return distance_miles\n",
    "\n",
    "def check_heading_dt(row):\n",
    "    if (row[\"dist_to_wtc_pickup\"] > row[\"dist_to_wtc_dropoff\"]) & (row[\"dist_to_wtc_dropoff\"] < 2):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def heading_to_airport(row):\n",
    "    if (row[\"dist_to_lag_pickup\"] > row[\"dist_to_lag_dropoff\"]) & (row[\"dist_to_lag_dropoff\"] < 3):\n",
    "        return 1\n",
    "    if (row[\"dist_to_nwk_pickup\"] > row[\"dist_to_nwk_dropoff\"]) & (row[\"dist_to_nwk_dropoff\"] <3):\n",
    "        return 1\n",
    "    if (row[\"dist_to_jfk_pickup\"] > row[\"dist_to_jfk_dropoff\"]) & (row[\"dist_to_jfk_dropoff\"] < 3):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_park = [40.778940,-73.962295]\n",
    "time_square = [40.758623,-73.985043]\n",
    "one_world_trade = [40.712613,-74.014262]\n",
    "laguardia = [40.776288,-73.872115]\n",
    "newark = [40.693711,-74.179404]\n",
    "jfk = [40.644195,-73.782446]\n",
    "data[\"dist_to_cp_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = central_park[0], loc_lng = central_park[1])\n",
    "data[\"dist_to_cp_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = central_park[0], loc_lng = central_park[1])\n",
    "data[\"dist_to_ts_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = time_square[0], loc_lng = time_square[1])\n",
    "data[\"dist_to_ts_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = time_square[0], loc_lng = time_square[1])\n",
    "data[\"dist_to_wtc_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = one_world_trade[0], loc_lng = one_world_trade[1])\n",
    "data[\"dist_to_wtc_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = one_world_trade[0], loc_lng = one_world_trade[1])\n",
    "data[\"dist_to_lag_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = laguardia[0], loc_lng = laguardia[1]) \n",
    "data[\"dist_to_lag_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = laguardia[0], loc_lng = laguardia[1])\n",
    "data[\"dist_to_nwk_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = newark[0], loc_lng = newark[1])\n",
    "data[\"dist_to_nwk_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = newark[0], loc_lng = newark[1])\n",
    "data[\"dist_to_jfk_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = jfk[0], loc_lng = jfk[1])\n",
    "data[\"dist_to_jfk_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = jfk[0], loc_lng = jfk[1])\n",
    "data[\"distance_traveled\"] = data.apply(get_distance, axis = 1)\n",
    "data[\"heading_dt\"] = data.apply(check_heading_dt, axis = 1)\n",
    "data[\"heading_to_airport\"] = data.apply(heading_to_airport, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance should be a straight forward measurement for cost of trip as well as teh amount of time the \n",
    "#trip took. we have a start time but I don't believe we have a drop off time.\n",
    "\n",
    "#the next low hanging fruit is obviously pickup time/day of week \n",
    "#we would expect rush hour times to have higher fares than late night or weekend\n",
    "\n",
    "#i wonder if we can plot the lat/lng values for pick up and drop off and see if there are some \"hot\" \n",
    "#areas that would coincide for high prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(df):\n",
    "    corr = df.corr()\n",
    "    \n",
    "    sns.set(style=\"white\")\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_correlation_heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pickup_datetime\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"], infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "data[\"day_of_week\"] = [datetime.weekday(x) for x in data[\"pickup_datetime\"]]\n",
    "data[\"hour_24\"] = [x.time().hour for x in data[\"pickup_datetime\"]]\n",
    "data[\"year\"] = [x.year for x in data[\"pickup_datetime\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,10))\n",
    "ax = sns.boxplot(x = \"year\", y = \"fare_amount\", data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize = (20,10))\n",
    "data.groupby('year')['fare_amount'].mean().plot(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there has been an obvious increase in average fare by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,10))\n",
    "ax = sns.boxplot(x = \"day_of_week\", y = \"fare_amount\", data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this isn't particularly helpful because of all the outliers above around $22\n",
    "fig,ax= plt.subplots(figsize = (20,10))\n",
    "data.groupby('day_of_week')['fare_amount'].mean().plot(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there isn't a lot of disparity between days only a range of $.60 on the mean from the lowest average\n",
    "#fare day to the highest. let's look at time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,10))\n",
    "ax = sns.boxplot(x = \"hour_24\", y = \"fare_amount\", data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again box plots are hard to distinguish except for the width of the 5am boxplot. \n",
    "fig,ax= plt.subplots(figsize = (20,10))\n",
    "data.groupby('hour_24')['fare_amount'].mean().plot(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we see a very large spike around 5 UTC time. this corresponds to roughly midnight on east coast \n",
    "#time. this appears to coincide with a fare spike late at night. we see another fare spike during the \n",
    "#morning rush hour between 7am and around noon. This appears to be a variable that will be of serious\n",
    "#use. We also see this is a highly nonlinear relationship. We can attempt to build this into a linear\n",
    "#model using dummy variables or we can use a decision tree model and not worry about building dummy\n",
    "#variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot our latitude and longitude values to see if high fares are associated with start lat/lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[\"pickup_longitude\"], data[\"pickup_latitude\"], c = data[\"fare_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(data[\"distance_traveled\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"distance_traveled\"] > 100]\n",
    "#these don't seem right. these people traveled hundreds of miles for less than $25. these should be\n",
    "#thrown out. let's restrict our latitude and longitudes more at the beginning and see those are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"distance_traveled\"] < 100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"day_of_week\"] = pd.Categorical(data[\"day_of_week\"])\n",
    "data[\"hour_24\"] = pd.Categorical(data[\"hour_24\"])\n",
    "data[\"year\"] = pd.Categorical(data[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "data = create_dummies(data, \"day_of_week\")\n",
    "data = create_dummies(data, \"hour_24\")\n",
    "data = create_dummies(data, \"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have all these new columns lets look at our new correlation map to see which features\n",
    "#are the most important to fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we see a few standouts with latitude and longitude of pickup and dropoff, and distance traveled,\n",
    "#a few of the hours. we can automate this by just grabbing it by a correlation cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data.corr()[\"fare_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_corrs = correlations.loc[abs(correlations) > .03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_corrs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'dist_to_cp_pickup',\n",
       " 'dist_to_cp_dropoff',\n",
       " 'dist_to_ts_pickup',\n",
       " 'dist_to_ts_dropoff',\n",
       " 'dist_to_wtc_pickup',\n",
       " 'dist_to_wtc_dropoff',\n",
       " 'dist_to_lag_dropoff',\n",
       " 'dist_to_nwk_pickup',\n",
       " 'dist_to_nwk_dropoff',\n",
       " 'dist_to_jfk_pickup',\n",
       " 'dist_to_jfk_dropoff',\n",
       " 'distance_traveled',\n",
       " 'heading_to_airport',\n",
       " 'hour_24_5',\n",
       " 'year_2009',\n",
       " 'year_2010',\n",
       " 'year_2011',\n",
       " 'year_2013',\n",
       " 'year_2014',\n",
       " 'year_2015']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_cols = [x for x in key_corrs.index if \"fare_amount\" not in x]\n",
    "key_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is probably a good setup to start with, even with hour 5 so low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LinearRegression(normalize = True)\n",
    "scores = cross_val_score(lr, data[key_cols], data['fare_amount'], scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "mean_error_lr = scores.mean()\n",
    "print(mean_error_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "hyperparameters = {\"criterion\": [\"mse\"],\n",
    "                   \"max_depth\": [5, 10,15],\n",
    "                   \"max_features\": [\"auto\",\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5],\n",
    "                   \"min_samples_split\": [2,5],\n",
    "                   \"n_estimators\": [5,10,20]\n",
    "}\n",
    "\n",
    "clf = RandomForestRegressor(random_state=1)\n",
    "grid = GridSearchCV(clf,param_grid=hyperparameters,cv=3)\n",
    "\n",
    "grid.fit(data[key_cols], data['fare_amount'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'criterion' : 'mse',\n",
    "    'max_depth': 15,\n",
    "    'max_features' : 'auto',\n",
    "    'min_samples_leaf': 5,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(random_state = 1)\n",
    "scores = cross_val_score(clf, data[key_cols], data['fare_amount'],scoring = \"neg_mean_squared_error\", cv= 5)\n",
    "mean_error_rf = scores.mean()\n",
    "print(mean_error_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(**best_params)\n",
    "clf.fit(data[key_cols], data['fare_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    #data = data[(data[\"pickup_latitude\"] <43) & (data[\"pickup_latitude\"] > 39)]\n",
    "    #data = data[(data[\"dropoff_latitude\"] <43) & (data[\"dropoff_latitude\"] > 39)]\n",
    "    #data = data[(data[\"pickup_longitude\"] < -73) & (data[\"pickup_longitude\"] > - 75)]\n",
    "    #data = data[(data[\"dropoff_longitude\"] <-73) & (data[\"dropoff_longitude\"] > -75)]\n",
    "    #data = data[(data[\"passenger_count\"] > 0) & (data[\"passenger_count\"] < 8)]\n",
    "    central_park = [40.778940,-73.962295]\n",
    "    time_square = [40.758623,-73.985043]\n",
    "    one_world_trade = [40.712613,-74.014262]\n",
    "    laguardia = [40.776288,-73.872115]\n",
    "    newark = [40.693711,-74.179404]\n",
    "    jfk = [40.644195,-73.782446]\n",
    "    data[\"dist_to_cp_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = central_park[0], loc_lng = central_park[1])\n",
    "    data[\"dist_to_cp_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = central_park[0], loc_lng = central_park[1])\n",
    "    data[\"dist_to_ts_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = time_square[0], loc_lng = time_square[1])\n",
    "    data[\"dist_to_ts_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = time_square[0], loc_lng = time_square[1])\n",
    "    data[\"dist_to_wtc_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = one_world_trade[0], loc_lng = one_world_trade[1])\n",
    "    data[\"dist_to_wtc_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = one_world_trade[0], loc_lng = one_world_trade[1])\n",
    "    data[\"dist_to_lag_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = laguardia[0], loc_lng = laguardia[1]) \n",
    "    data[\"dist_to_lag_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = laguardia[0], loc_lng = laguardia[1])\n",
    "    data[\"dist_to_nwk_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = newark[0], loc_lng = newark[1])\n",
    "    data[\"dist_to_nwk_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = newark[0], loc_lng = newark[1])\n",
    "    data[\"dist_to_jfk_pickup\"] = data.apply(distance_from_pickup, axis = 1, loc_lat = jfk[0], loc_lng = jfk[1])\n",
    "    data[\"dist_to_jfk_dropoff\"] = data.apply(distance_from_dropoff, axis = 1, loc_lat = jfk[0], loc_lng = jfk[1])\n",
    "    data[\"distance_traveled\"] = data.apply(get_distance, axis = 1)\n",
    "    data[\"heading_dt\"] = data.apply(check_heading_dt, axis = 1)\n",
    "    data[\"heading_to_airport\"] = data.apply(heading_to_airport, axis= 1)\n",
    "\n",
    "    data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"], infer_datetime_format = True)\n",
    "    data[\"day_of_week\"] = [datetime.weekday(x) for x in data[\"pickup_datetime\"]]\n",
    "    data[\"hour_24\"] = [x.time().hour for x in data[\"pickup_datetime\"]]\n",
    "    data[\"year\"] = [x.year for x in data[\"pickup_datetime\"]]\n",
    "    #data = data[data[\"distance_traveled\"] < 100] \n",
    "    data = create_dummies(data, \"day_of_week\")\n",
    "    data = create_dummies(data, \"hour_24\")\n",
    "    data = create_dummies(data, \"year\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>2015-01-27 13:08:24 UTC</td>\n",
       "      <td>-73.973320</td>\n",
       "      <td>40.763805</td>\n",
       "      <td>-73.981430</td>\n",
       "      <td>40.743835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>2015-01-27 13:08:24 UTC</td>\n",
       "      <td>-73.986862</td>\n",
       "      <td>40.719383</td>\n",
       "      <td>-73.998886</td>\n",
       "      <td>40.739201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>2011-10-08 11:53:44 UTC</td>\n",
       "      <td>-73.982524</td>\n",
       "      <td>40.751260</td>\n",
       "      <td>-73.979654</td>\n",
       "      <td>40.746139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>2012-12-01 21:12:12 UTC</td>\n",
       "      <td>-73.981160</td>\n",
       "      <td>40.767807</td>\n",
       "      <td>-73.990448</td>\n",
       "      <td>40.751635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>2012-12-01 21:12:12 UTC</td>\n",
       "      <td>-73.966046</td>\n",
       "      <td>40.789775</td>\n",
       "      <td>-73.988565</td>\n",
       "      <td>40.744427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key          pickup_datetime  pickup_longitude  \\\n",
       "0  2015-01-27 13:08:24.0000002  2015-01-27 13:08:24 UTC        -73.973320   \n",
       "1  2015-01-27 13:08:24.0000003  2015-01-27 13:08:24 UTC        -73.986862   \n",
       "2  2011-10-08 11:53:44.0000002  2011-10-08 11:53:44 UTC        -73.982524   \n",
       "3  2012-12-01 21:12:12.0000002  2012-12-01 21:12:12 UTC        -73.981160   \n",
       "4  2012-12-01 21:12:12.0000003  2012-12-01 21:12:12 UTC        -73.966046   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.763805         -73.981430         40.743835                1  \n",
       "1        40.719383         -73.998886         40.739201                1  \n",
       "2        40.751260         -73.979654         40.746139                1  \n",
       "3        40.767807         -73.990448         40.751635                1  \n",
       "4        40.789775         -73.988565         40.744427                1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = transform_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_data[key_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = test_data['key']\n",
    "submission_dict = {\n",
    "    'key' : keys,\n",
    "    'fare_amount': predictions.round(2)\n",
    "}\n",
    "\n",
    "submission_df = pd.DataFrame(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_in_order = ['key','fare_amount']\n",
    "submission_df = submission_df[cols_in_order]\n",
    "submission_df.head()\n",
    "submission_df.to_csv(\"taxi_submission1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(test_data[\"distance_traveled\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
